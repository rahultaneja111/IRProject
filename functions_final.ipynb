{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Team Project: Web Search and Information Retrieval - Topic 4: Effiecient Vector Retrieval**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# IR_project _v.31 _functions "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook contains \"own implementations\" of methods used in VSM retrieval."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# last edit - 05/26/2019"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Overview of function and methods: "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "q = Query, d = single document, D = document collection {d1, d2, ..., dn}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. **Indexing**\n",
    "        1.1 preprocess(d): \"Preprocess raw document\"\n",
    "        1.2 compute_Tf(d, binary=False): \"Compute raw term-frequency (tf)\"\n",
    "        1.3 compute_Idf(D): \"Compute inverse document-frequency (idf)\"\n",
    "        1.4a compute_TfIdf(D): \"Compute tf-idf\"\n",
    "        1.4b compute_TfIdfQuery(q, idfDictionary): \"Compute tf-idf scores for each term t in query q\"\n",
    "        1.5 construct_invertedIndex(D): \"Construct an inverted index across all documents in D.\n",
    "                                         Format: {\"term\": [(docID1, tf-idf), (docID2, tf-idf), etc.]}\n",
    "        1.6 construct_docLengthDict(D): \"Computes the document length for each document in D and stores this\n",
    "                                        information in a seperate dictionary\"\n",
    "        1.7 create_tdm(D):\n",
    "        1.8 construct_tiered_index():\n",
    "        \n",
    "2. **Retrieval**\n",
    "        2.1 vec_cosine(a, b): \"Computes cosine between two vectors a and b. Not used!\"\n",
    "        2.2 cosine_scores(q, D): \"Computes cosine scores between each document in D and a given query q\"\n",
    "        2.2a cosine_scores_postingMerge(q, D, I, L, idfDict)\n",
    "        2.2b cosine_scores_pre_cluster(q, D, I, L, idfDict, preClusterDict, k)\n",
    "        2.2c cosine_scores_tiered(q, D, T, L, idfDict, k)\n",
    "        2.3 top_k_retrieval(q, D, k): \"Ranks cosine scores and returns only k-highest ranked documents\"\n",
    "        \n",
    "3. **EfficientRetrieval**\n",
    "        3.1 intersection(sets)\n",
    "        3.2 pre_cluster(D)\n",
    "        \n",
    "4. **Evaluation**\n",
    "        4.1 evaluate_pAtRank()\n",
    "        4.2 evaluate_AveragePrecision()\n",
    "        4.3 evaluate_nDCG()\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. *Indexing*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Libaries and Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to /home/roman/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Using nltk lemmatizer requires to download the WordNetDictionary first!\n",
    "import nltk\n",
    "nltk.download('wordnet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import math\n",
    "import copy\n",
    "import scipy\n",
    "from time import time\n",
    "from functools import reduce \n",
    "from random import randint\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.corpus import wordnet\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk.stem import SnowballStemmer             "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1 preprocess()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List of regex to be tested for tokenization:\n",
    "# Naive: \"[a-z\\-]+\"\n",
    "# More advanced: \"(?u)\\\\b\\\\w\\\\w+\\\\b\"\n",
    "def preprocess(d, regex=\"(?u)\\\\b\\\\w\\\\w+\\\\b\", stopwordList=\"data/raw/stopwords.large\",\n",
    "               lemmatizeTokens=False, stemmPorter=True, stemmSnowball=False):\n",
    "    \n",
    "    \"\"\"Input: Single document d, regular expression that is used for tokenization, path to stopword list.\n",
    "    Splits all terms in d according to given tokenizer, converts terms to lower case,\n",
    "    removes stopwords. Returns a list of preprocessed terms\"\"\"\n",
    "\n",
    "    terms = list()\n",
    "\n",
    "    stopwords = open(stopwordList).read()\n",
    "    stopwords = stopwords.split(sep=\"\\n\")\n",
    "    tokenizer = re.compile(regex, re.IGNORECASE)  # letters a-z, -, and ''\n",
    "    if lemmatizeTokens:\n",
    "        lemmatizer = WordNetLemmatizer()\n",
    "    if stemmSnowball:\n",
    "        stemmer = SnowballStemmer(language='english')\n",
    "    if stemmPorter:\n",
    "        stemmer = PorterStemmer()\n",
    "\n",
    "    for term in tokenizer.findall(d):\n",
    "\n",
    "        # lower case\n",
    "        term = term.lower()\n",
    "\n",
    "        # remove stopwords\n",
    "        if term not in stopwords:\n",
    "\n",
    "            # if true lemmatize tokens\n",
    "            if lemmatizeTokens:\n",
    "                term = lemmatizer.lemmatize(term)\n",
    "\n",
    "            # if true stemm tokens\n",
    "            if stemmPorter or stemmSnowball:\n",
    "\n",
    "                term = stemmer.stem(term)\n",
    "\n",
    "            terms.append(term)\n",
    "\n",
    "    return terms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 compute_Tf()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_Tf(d, rawScores=False, binary=False):\n",
    "    \n",
    "    \"\"\"Input: Single document d. Calls preprocess(). For each preprocessed term t in document d it computes\n",
    "    normalized (or raw) term-frequency of t in d. Returns dictionary\"\"\"\n",
    "\n",
    "    Tfs = dict()\n",
    "\n",
    "    # preprocess terms t calling preprocess():\n",
    "    terms = preprocess(d)\n",
    "\n",
    "    for term in terms:\n",
    "\n",
    "        if term in Tfs and not binary:\n",
    "            Tfs[term] += 1\n",
    "        else:\n",
    "            Tfs[term] = 1\n",
    "\n",
    "    if rawScores:\n",
    "        return Tfs\n",
    "\n",
    "    # Find maximum Tf value:\n",
    "    maximum = max(Tfs, key=Tfs.get)\n",
    "    maxTf = 1 + math.log10(Tfs[maximum])\n",
    "\n",
    "    # Normalize Tf scores using logarithm and divide by maximum Tf score\n",
    "    for term in Tfs:\n",
    "\n",
    "        if Tfs[term] > 0:\n",
    "\n",
    "            Tfs[term] = (1 + math.log10(Tfs[term])) / (maxTf)\n",
    "\n",
    "    return Tfs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3 compute_Idf()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_Idf(D, tfDict=None, verbose=True):\n",
    "    \n",
    "    \"\"\"Input: Document collection D. If tf scores are not provided \n",
    "    compute tf first. Then compute document frequency df and inverse document\n",
    "    frequency idf for each term t in document collection D. Return dictionary with idf values\"\"\"\n",
    "\n",
    "    t0 = time()\n",
    "\n",
    "    Idfs = dict()      # dict that holds inverse-document frequency (idf) scores\n",
    "    Dfs = dict()       # dict that holds document-frequency (df) scores\n",
    "    Tfs = dict()       # dict that holds (normalized) term-frequency (tf) scores\n",
    "\n",
    "    # If tf scores are not provided, call computeTf()\n",
    "    if tfDict is None:\n",
    "        for doc in D.keys():\n",
    "            Tfs[doc] = compute_Tf(D[doc])\n",
    "    else:\n",
    "        Tfs = copy.deepcopy(tfDict)\n",
    "\n",
    "    # Compute df for each term in document collection D\n",
    "    for doc in Tfs.keys():\n",
    "        for term in Tfs[doc]:\n",
    "\n",
    "            if term in Dfs and Tfs[doc][term] > 0:\n",
    "                Dfs[term] += 1\n",
    "            else:\n",
    "                Dfs[term] = 1\n",
    "\n",
    "    # Compute number of document in the document collection!!!!\n",
    "    N = len(D.keys())\n",
    "\n",
    "    # Compute idf for each term\n",
    "    for term in Dfs.keys():\n",
    "        Idfs[term] = math.log10(N / Dfs[term])\n",
    "\n",
    "    if verbose:\n",
    "        print(\"Idf computation done in {:.4f}s.\".format(time() - t0))\n",
    "\n",
    "    return Idfs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.4a compute_TfIdf()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_TfIdf(D, idfDict=None, verbose=True):\n",
    "    \n",
    "    \"\"\"Input: Document collection D. Optional: idf scores. Compute tf-idf values for each term \n",
    "    t across all documnets d in document collection D. Return dictionary with tf-idf scores.\"\"\"\n",
    "\n",
    "    t0 = time()\n",
    "\n",
    "    TfIdfs = dict()\n",
    "    Idfs = dict()\n",
    "    Tfs = dict()\n",
    "\n",
    "    # If idf scores are not provided call compute_Idf()\n",
    "    if idfDict is None:\n",
    "        Idfs = compute_Idf(D)\n",
    "    else:\n",
    "        Idfs = idfDict\n",
    "\n",
    "    # Compute term-frequencies for all documents d in D\n",
    "    for doc in D.keys():\n",
    "        Tfs[doc] = compute_Tf(D[doc])\n",
    "\n",
    "    # compute Tf-Idf scores for each t across all documents in D\n",
    "    TfIdfs = copy.deepcopy(Tfs)\n",
    "\n",
    "    for doc in D.keys():\n",
    "        for term in Idfs:\n",
    "            # check if term is part of document d\n",
    "            if term in Tfs[doc]:\n",
    "                # if tf > 0\n",
    "                if Tfs[doc][term] > 0:\n",
    "                    # tfidf = normalized tf * idf\n",
    "                    TfIdfs[doc][term] = Tfs[doc][term] * Idfs[term]\n",
    "\n",
    "                else:\n",
    "                    TfIdfs[doc][term] = 0\n",
    "\n",
    "            else:\n",
    "                continue\n",
    "\n",
    "    if verbose:\n",
    "        print(\"Tf-idf computation done in {:.4f}s.\".format(time() - t0))\n",
    "\n",
    "    return TfIdfs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.4b compute_TfIdfQuery()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_TfIdfQuery(q, idfDict):\n",
    "    \n",
    "    \"\"\"Input: Query q, and Idf dictionary. For each term t in query q compute tf-idf scores.\n",
    "    Return dictionary of tf-idf scores.\"\"\"\n",
    "\n",
    "    Tfidf_query = dict()\n",
    "    Idfs = idfDict\n",
    "\n",
    "    # Compute term frequency for each term t in query q\n",
    "    Tf_query = compute_Tf(q)\n",
    "\n",
    "    # Transform tf scores into tf-idf scores using global idf for each term t\n",
    "    for term in Tf_query.keys():\n",
    "\n",
    "        if term in Idfs.keys():\n",
    "\n",
    "            Tfidf_query[term] = Tf_query[term] * Idfs[term]\n",
    "\n",
    "    return Tfidf_query"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.5 construct_inverted_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def construct_invertedIndex(D, idfDict=None, tfidfDict=None, verbose=True):\n",
    "    \n",
    "    \"\"\"Input: Document collection D. For each document d in D compute Tf-Idf across all terms\n",
    "    t in document d. For each term t add tuple(docID, tf-idf) to posting list in inverted index.\"\"\"\n",
    "\n",
    "    t0 = time()\n",
    "\n",
    "    invertedIndex = dict()\n",
    "    TfIdfs = dict()\n",
    "\n",
    "    # compute idf scores\n",
    "    if idfDict is None:\n",
    "        Idfs = compute_Idf(D)\n",
    "    else:\n",
    "        Idfs = idfDict\n",
    "\n",
    "    # compute tfidf scores\n",
    "    if tfidfDict is None:\n",
    "        TfIdfs = compute_TfIdf(D, Idfs)\n",
    "    else:\n",
    "        TfIdfs = tfidfDict\n",
    "\n",
    "    # Add tuple(docID, tf-idf) to postinglist for each term in vocabulary\n",
    "    for doc in D.keys():\n",
    "\n",
    "        for term in TfIdfs[doc]:\n",
    "\n",
    "            e = (doc, TfIdfs[doc][term])\n",
    "\n",
    "            if term in invertedIndex.keys():\n",
    "                invertedIndex[term].append(e)\n",
    "\n",
    "            else:\n",
    "                invertedIndex[term] = [e, ]\n",
    "\n",
    "    if verbose:\n",
    "        print(\"InvertedIndex construction done in {:.4f}s.\".format(\n",
    "            time() - t0))\n",
    "\n",
    "    return invertedIndex"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.6 doc_length()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def construct_docLengthDict(D, tfidfDict=None, verbose=True):\n",
    "    \n",
    "    \"\"\"Input: Document collection D. For each document d in D vector norm length of d.\n",
    "    Return dictionary {docID : docLength}\"\"\"\n",
    "\n",
    "    t0 = time()\n",
    "\n",
    "    docLength = dict()\n",
    "\n",
    "    if tfidfDict is None:\n",
    "        tfidfDict = compute_TfIdf(D)\n",
    "\n",
    "    for doc in tfidfDict.keys():\n",
    "\n",
    "        docLength[doc] = 0\n",
    "\n",
    "        for term in tfidfDict[doc]:\n",
    "\n",
    "            docLength[doc] += math.pow(tfidfDict[doc][term], 2)\n",
    "\n",
    "        docLength[doc] = math.sqrt(docLength[doc])\n",
    "\n",
    "    if verbose:\n",
    "        print(\"DocLength index construction done in {:.4f}s.\".format(\n",
    "            time() - t0))\n",
    "\n",
    "    return docLength"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.7 create_tdm()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_tdm(D, tfidfDict=None, verbose=True):\n",
    "    \n",
    "    \"\"\"Input: Document collection D. Call compute_TfIdf() and calculate tf-idf values for each term in \n",
    "    document collection. Return term-document matrix (tdm) as pd.DataFrame\"\"\"\n",
    "\n",
    "    t0 = time()\n",
    "\n",
    "    TfIdfs = dict()\n",
    "\n",
    "    # call compute_TfIdf()\n",
    "    if tfidfDict is None:\n",
    "        TfIdfs = compute_TfIdf(D)\n",
    "    else:\n",
    "        TfIdfs = copy.deepcopy(tfidfDict)\n",
    "\n",
    "    # convert into pandas data frame\n",
    "    TfIdfs_df = pd.DataFrame(TfIdfs).fillna(0)\n",
    "\n",
    "    if verbose:\n",
    "        print(\"TDM construction done in {:.4f}s.\".format(time() - t0))\n",
    "\n",
    "    return TfIdfs_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.8 construct_tiered_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def construct_tiered_index(D, inv_index_dict=None, t=0.8, verbose=True):\n",
    "    \n",
    "    \"\"\"Add some DocString here\"\"\"\n",
    "    \n",
    "    t0 = time()\n",
    "    tieredIndex = dict()\n",
    "\n",
    "    # compute inverted index\n",
    "    if inv_index_dict is None:\n",
    "        invertedIndex = construct_invertedIndex(D)\n",
    "    else:\n",
    "        invertedIndex = inv_index_dict\n",
    "\n",
    "    for term in invertedIndex.keys():\n",
    "        inv_index_list = invertedIndex[term]\n",
    "        tier1, tier2 = [], []\n",
    "\n",
    "        # Create 2 level tiered index\n",
    "        for item in inv_index_list:\n",
    "\n",
    "            if item[1] >= t:  # Set this level to decide on the split based on the TF- IDF score\n",
    "                tier1.append(item)\n",
    "            else:\n",
    "                tier2.append(item)\n",
    "\n",
    "            tier_list = [tier1, tier2]\n",
    "\n",
    "        tieredIndex[term] = tier_list\n",
    "        \n",
    "    if verbose:\n",
    "        print(\"TieredIndex construction done in {:.4f}s.\".format(time() - t0))\n",
    "\n",
    "    return tieredIndex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. *QUERYING*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 vanilla_cosine()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def vec_cosine(v1, v2):\n",
    "    \n",
    "    \"\"\"Input: Two vectors. Calculate cosine score between both input vectors using numpy.\"\"\"\n",
    "\n",
    "    return float(np.dot(v1, v2) / (np.linalg.norm(v1) * np.linalg.norm(v2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def vanilla_cosine(q, TDM, idfDict):\n",
    "    \n",
    "    \"\"\"Input: Query q, Term-document matrix with tf-idf scores, Idf dictionary. Compute tf-idf scores\n",
    "    for each term t in query q. Then append vector and add query q to tdm. Calculate cosine simalrity between\n",
    "    each document d in D (each column in tdm) and query q. Store results and return dictionary.\"\"\"\n",
    "\n",
    "    Tfidf_query = dict()    \n",
    "    Vector_q = dict()       \n",
    "    scores = dict() \n",
    "\n",
    "    # Calculate tfidf scores for each term in query q\n",
    "    Tfidf_query = compute_TfIdfQuery(q, idfDict)\n",
    "\n",
    "    # add query vetor to tdm \n",
    "    for term in TDM.index:\n",
    "\n",
    "        if term in Tfidf_query:\n",
    "            Vector_q[term] = Tfidf_query[term]\n",
    "        else:\n",
    "            Vector_q[term] = 0\n",
    "\n",
    "    TDM['query'] = Vector_q.values()\n",
    "\n",
    "    # calculate cosine:\n",
    "    for col in TDM:\n",
    "        scores[col] = vec_cosine(TDM['query'], TDM[col])\n",
    "\n",
    "    del scores[\"query\"]\n",
    "\n",
    "    return scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 cosine_scores()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# **Note that this is already a more efficient version of cosine computation.\n",
    "\n",
    "def cosine_scores(q, D, I, L, idfDict):\n",
    "    \"\"\"Using inverted index. Code see lecture 4, slide 28. QUESTION: What is meant with \n",
    "    normalization: document length or vector norm? \"\"\"\n",
    "\n",
    "    tf_idf_query = dict()     # holds tf_idf scores for each term in q\n",
    "    scores = dict()           # holds scores cos(q, d) for each document d in D\n",
    "\n",
    "    # Initialize scores with zeros\n",
    "    for idx in D.keys():\n",
    "        key_ = idx\n",
    "        value_ = 0\n",
    "        scores.update({key_: value_})\n",
    "\n",
    "    tf_idf_query = compute_TfIdfQuery(q, idfDict)\n",
    "    \n",
    "    \n",
    "    # CORE IMPLEMENTATION OF COSINE Similarity \n",
    "    # Follows the pseudo-code given in Lecture 4, slide 28.\n",
    "    \n",
    "    # for each query term t\n",
    "    for term in tf_idf_query.keys():\n",
    "\n",
    "        # assign tf-idf of term t in query q to w_tq\n",
    "        w_tq = tf_idf_query[term]\n",
    "\n",
    "        # if term is in invertedIndex\n",
    "        if term in I.keys():\n",
    "\n",
    "            # fetch posting list for term t\n",
    "            posting_list = I[term]\n",
    "\n",
    "            # for each tuple (docID, tf-idf of term t in document d)\n",
    "            for tuple_ in posting_list:\n",
    "\n",
    "                docID = tuple_[0]\n",
    "                w_td = tuple_[1]\n",
    "\n",
    "                scores[docID] += (w_td * w_tq)\n",
    "\n",
    "        else:\n",
    "            continue\n",
    "\n",
    "    # normalize scores with document length.\n",
    "    for doc in scores.keys():\n",
    "        if scores[doc] > 0:\n",
    "            scores[doc] /= L[doc]\n",
    "\n",
    "    return scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2a cosine_scores_postingMerge()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cosine_scores_postingMerge(q, D, I, L, idfDict, postingMergeIntersection=False):\n",
    "    \n",
    "    \"\"\"Using inverted index. Code see lecture 4, slide 28. QUESTION: What is meant with \n",
    "    normalization: document length or vector norm? \"\"\"\n",
    "\n",
    "    tf_idf_query = dict()     # holds tf_idf scores for each term in q\n",
    "    scores = dict()           # holds scores cos(q, d) for each document d in D\n",
    "\n",
    "    # Initialize scores with zeros\n",
    "    for idx in D.keys():\n",
    "        key_ = idx\n",
    "        value_ = 0\n",
    "        scores.update({key_: value_})\n",
    "\n",
    "    tf_idf_query = compute_TfIdfQuery(q, idfDict)\n",
    "\n",
    "    # if posting merge: compute intersection of postings lists\n",
    "    if postingMergeIntersection:\n",
    "        relevant_document_ids = intersection(\n",
    "            [set([t[0] for t in I[term]]) for term in tf_idf_query.keys()])\n",
    "    \n",
    "    # check if set of relevant documents is empty!\n",
    "    if relevant_document_ids:\n",
    "        \n",
    "        # for each query term t\n",
    "        for term in tf_idf_query.keys():\n",
    "\n",
    "            # assign tf-idf of term t in query q to w_tq\n",
    "            w_tq = tf_idf_query[term]\n",
    "\n",
    "            # if term is in invertedIndex\n",
    "            if term in I.keys():\n",
    "\n",
    "                # fetch posting list for term t\n",
    "                posting_list = I[term]\n",
    "\n",
    "                # for each tuple (docID, tf-idf of term t in document d)\n",
    "                for tuple_ in posting_list:\n",
    "\n",
    "                    # assigne document id to docID\n",
    "                    docID = tuple_[0]\n",
    "\n",
    "                    # check if docID is in set of relevant_document_ids\n",
    "                    if docID in relevant_document_ids:\n",
    "\n",
    "                        w_td = tuple_[1]\n",
    "                        \n",
    "                        scores[docID] += (w_td * w_tq)\n",
    "\n",
    "                        #if docID in scores:\n",
    "                         #   scores[docID] += (w_td * w_tq)\n",
    "\n",
    "                        #else:\n",
    "                         #   scores[docID] = (w_td * w_tq)\n",
    "                    else:\n",
    "                        continue\n",
    "\n",
    "            else:\n",
    "                continue\n",
    "    \n",
    "    \n",
    "    # normalize scores with document length.\n",
    "    for doc in scores.keys():\n",
    "        if scores[doc] != 0:\n",
    "            scores[doc] /= L[doc]\n",
    "    \n",
    "    \n",
    "    return scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2b cosine_scores_pre_cluster()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cosine_scores_pre_cluster(q, D, I, L, idfDict, preClusterDict, k=30,):\n",
    "    \n",
    "    \"\"\"Own pre_clustering implementation, Lecture 4 slide P34, P35\"\"\"\n",
    "\n",
    "    tf_idf_query = dict()        # holds tf_idf scores for each term in q\n",
    "    scores_leaders = dict()      # holds scores cos(q, d) for each document d in list of cluster leaders!\n",
    "    scores = dict()              # holds scores cos(q, d) for each document d in D\n",
    "\n",
    "    clusters = preClusterDict\n",
    "    \n",
    "    # Initialize scores with zeros!\n",
    "    for idx in D.keys():\n",
    "        key_ = idx\n",
    "        value_ = 0\n",
    "        scores.update({key_: value_})\n",
    "\n",
    "    # Initialize scores_leaders with zeros!\n",
    "    for idx in clusters.keys():\n",
    "        key_ = idx\n",
    "        value_ = 0\n",
    "        scores_leaders.update({key_: value_})\n",
    "\n",
    "    tf_idf_query = compute_TfIdfQuery(q, idfDict)\n",
    "    \n",
    "    \n",
    "    ### STEP 1: Compute cosine between query and cluster leaders!\n",
    "    leader_documents_ids = clusters.keys()\n",
    "\n",
    "    # for each query term t\n",
    "    for term in tf_idf_query.keys():\n",
    "\n",
    "       # assign tf-idf of term t in query q to w_tq\n",
    "        w_tq = tf_idf_query[term]\n",
    "\n",
    "        # if term is in invertedIndex\n",
    "        if term in I.keys():\n",
    "            \n",
    "            # fetch posting list for term t\n",
    "            posting_list = I[term]\n",
    "            \n",
    "            # for each tuple (docID, tf-idf of term t in document d)\n",
    "            for tuple_ in posting_list:\n",
    "                \n",
    "                # assigne document id to docID\n",
    "                docID = tuple_[0]\n",
    "\n",
    "                # check if docID is in set of cluster leaders\n",
    "                if docID in leader_documents_ids:\n",
    "\n",
    "                    w_td = tuple_[1]\n",
    "                    \n",
    "                    scores_leaders[docID] += w_td * w_tq\n",
    "\n",
    "                \n",
    "                else:\n",
    "                    continue\n",
    "        else:\n",
    "\n",
    "            continue\n",
    "    \n",
    "    \n",
    "    # normalize scores with document length.\n",
    "    for doc in scores_leaders.keys():\n",
    "        if scores_leaders[doc] != 0:\n",
    "            scores_leaders[doc] /= L[doc]\n",
    "    \n",
    "    \n",
    "    # rank cosine scores of leaders\n",
    "    ranking = list()\n",
    "\n",
    "    for (id_, score_) in scores_leaders.items():\n",
    "        tuple_ = (id_, score_)\n",
    "        ranking.append(tuple_)\n",
    "\n",
    "    ranking = sorted(ranking, key=getKeyForSorting, reverse=True)\n",
    "    \n",
    "    \n",
    "    ### STEP 2: Compute cosine between query and all documents in cluster of max cluster leader!\n",
    "    ### If we retrieve less than k=30 documents go to the cluster of the second cluster leader\n",
    "    \n",
    "    ranking_list_index = 0                # start with cluster leader max\n",
    "    counter = 0                           # count number of docs found in cluster!\n",
    "    \n",
    "    while (counter < k and ranking_list_index < len(ranking)):\n",
    "\n",
    "        relevant_document_ids = clusters[ranking[ranking_list_index][0]]\n",
    "\n",
    "        for term in tf_idf_query.keys():\n",
    "\n",
    "            # assign tf-idf of term t in query q to w_tq\n",
    "            w_tq = tf_idf_query[term]\n",
    "\n",
    "            # if term is in invertedIndex\n",
    "            if term in I.keys():\n",
    "                \n",
    "                # fetch posting list for term t\n",
    "                posting_list = I[term]\n",
    "                \n",
    "                # for each tuple (docID, tf-idf of term t in document d)\n",
    "                for tuple_ in posting_list:\n",
    "                    \n",
    "                    \n",
    "                    # assigne document id to docID\n",
    "                    docID = tuple_[0]\n",
    "                    \n",
    "                    # check if docID is in set of relevant_document_ids\n",
    "                    if docID in relevant_document_ids:\n",
    "                        \n",
    "                        w_td = tuple_[1]\n",
    "                        \n",
    "                        scores[docID] += w_td * w_tq\n",
    "                    \n",
    "                        #if docID in scores:\n",
    "                         #   scores[docID] += w_td * w_tq\n",
    "                        #else:\n",
    "                         #   scores[docID] = w_td * w_tq\n",
    "                    \n",
    "                    else:\n",
    "                        continue\n",
    "            else:\n",
    "                continue\n",
    "\n",
    "        # Normalize scores and count number of relevant (i.e non zero documents in cluster)     \n",
    "        for doc in scores.keys():\n",
    "            \n",
    "            if doc in relevant_document_ids and scores[doc] != 0:\n",
    "                counter += 1\n",
    "                scores[doc] /= L[doc]\n",
    "\n",
    "        ranking_list_index += 1         # update index to go to next cluster!\n",
    "    \n",
    "    \n",
    "    # Return scores\n",
    "    return scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2c cosine_scores_tiered()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cosine_scores_tiered(\n",
    "    q,\n",
    "    D,\n",
    "    T,\n",
    "    L,\n",
    "    idfDict,\n",
    "    k,\n",
    "):\n",
    "    \"\"\"Own tiered index implementation, Lecture 4 slide P41, P42\"\"\"\n",
    "\n",
    "    tf_idf_query = dict()  # holds tf_idf scores for each term in q\n",
    "    scores = dict()  # holds scores cos(q, d) for each document d in D\n",
    "    pl_tier2 = []\n",
    "\n",
    "    # Initialize scores with zeros!\n",
    "\n",
    "    for idx in D.keys():\n",
    "        key_ = idx\n",
    "        value_ = 0\n",
    "        scores.update({key_: value_})\n",
    "\n",
    "    tf_idf_query = compute_TfIdfQuery(q, idfDict)\n",
    "\n",
    "    # ## THIS IS THE CORE IMPLEMENTATION OF COSINE CALCULATION ###\n",
    "    # for each query term t\n",
    "    for term in tf_idf_query.keys():\n",
    "\n",
    "        w_tq = tf_idf_query[term]\n",
    "\n",
    "        if term in T.keys():\n",
    "\n",
    "            posting_list = T[term]\n",
    "\n",
    "            pl_tier1 = posting_list[0]  # tier 1\"\n",
    "\n",
    "            for tuple_ in pl_tier1:  # check the tuple in tier1\n",
    "\n",
    "                docID = tuple_[0]\n",
    "\n",
    "                w_td = tuple_[1]\n",
    "\n",
    "                if docID in scores:\n",
    "                    \n",
    "                    scores[docID] += w_td * w_tq\n",
    "                    \n",
    "                else:\n",
    "\n",
    "                    scores[docID] = w_td * w_tq\n",
    "        else:\n",
    "\n",
    "            continue\n",
    "\n",
    "    counter = 0\n",
    "    for doc in scores.keys():\n",
    "        if scores[doc] > 0:\n",
    "            counter += 1\n",
    "\n",
    "    if counter < k:\n",
    "\n",
    "        for term in tf_idf_query.keys():\n",
    "\n",
    "            w_tq = tf_idf_query[term]\n",
    "\n",
    "        # if term is in invertedIndex\n",
    "            if term in T.keys():\n",
    "\n",
    "                # fetch posting list for term t\n",
    "                posting_list = T[term]\n",
    "\n",
    "                pl_tier2 = posting_list[1]  # tier 2\"\n",
    "                for tuple_ in pl_tier2:  # check the tuple in tier2\n",
    "                    docID = tuple_[0]\n",
    "                    w_td = tuple_[1]\n",
    "\n",
    "                    if docID in scores:\n",
    "                        scores[docID] += w_td * w_tq\n",
    "                    else:\n",
    "                        scores[docID] = w_td * w_tq\n",
    "            else:\n",
    "\n",
    "                continue\n",
    "\n",
    "    # normalize scores with document length.\n",
    "    for doc in scores.keys():\n",
    "        if scores[doc] > 0:\n",
    "            #counter += 1\n",
    "            scores[doc] /= L[doc]\n",
    "\n",
    "    return scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3 top_k_retrieval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# **Idea:** This will be the main function of our Retrieval system.\n",
    "# Based on strategy = ['vanilla', 'standard', 'intersection', 'preClustering', 'tiered']\n",
    "# it will call a different fucntion to compute cosine scores\n",
    "def getKeyForSorting(item):\n",
    "    return item[1]\n",
    "\n",
    "\n",
    "def top_k_retrieval(\n",
    "    q,\n",
    "    D,\n",
    "    k,\n",
    "    strategy='standard',\n",
    "    idfDict=None,\n",
    "    invertedIdx=None,\n",
    "    lengthIdx=None,\n",
    "    preClusterDict=None,\n",
    "    tieredIdx=None,\n",
    "    TDM=None,\n",
    "    show_documents=False,\n",
    "    return_results=False,\n",
    "    print_scores=True,\n",
    "    return_speed=False,\n",
    "    ):\n",
    "    \n",
    "    \"\"\"Input: Precomputed cosine scores, or query q and document collection D. Compute cosine scores between\n",
    "    document d and query q. Convert dictionary entries to list and sort according to \n",
    "    cosine score. Return only top k entries with highest similarity between q and d.\"\"\"\n",
    "\n",
    "    t0 = time()\n",
    "\n",
    "    # compute cosine scores:\n",
    "    if strategy == 'intersection':\n",
    "        scores = cosine_scores_postingMerge(q, D, invertedIdx, lengthIdx,\n",
    "                idfDict, postingMergeIntersection=True)\n",
    "    elif strategy == 'vanilla':\n",
    "        scores = vanilla_cosine(q, TDM, idfDict)\n",
    "    elif strategy == 'preclustering':\n",
    "        scores = cosine_scores_pre_cluster(\n",
    "            q,\n",
    "            D,\n",
    "            invertedIdx,\n",
    "            lengthIdx,\n",
    "            idfDict,\n",
    "            preClusterDict,\n",
    "            k=30,\n",
    "            )\n",
    "    elif strategy == 'tiered':\n",
    "        scores = cosine_scores_tiered(\n",
    "            q=q,\n",
    "            D=D,\n",
    "            T=tieredIdx,\n",
    "            L=lengthIdx,\n",
    "            idfDict=idfDict,\n",
    "            k=30,\n",
    "            )\n",
    "    else:\n",
    "        scores = cosine_scores(q, D, invertedIdx, lengthIdx, idfDict)\n",
    "\n",
    "        \n",
    "    # rank the returned scores\n",
    "    ranking = list()\n",
    "\n",
    "    for (id_, score_) in scores.items():\n",
    "        tuple_ = (id_, score_)\n",
    "        ranking.append(tuple_)\n",
    "\n",
    "    ranking = sorted(ranking, key=getKeyForSorting, reverse=True)\n",
    "    \n",
    "    # append only topK scores to topK_list\n",
    "    topK = list()\n",
    "    for i in range(k):\n",
    "        topK.append(ranking[i])\n",
    "    \n",
    "    # compute retrieval time\n",
    "    retrieval_speed = time() - t0\n",
    "    \n",
    "    # if true print retrieval time and cosine scores summary\n",
    "    if print_scores:\n",
    "        print('=' * 50)\n",
    "        print('Retrieval time ca. {:.8f} seconds.'.format(retrieval_speed))\n",
    "        print('Highest cosine similarity:')\n",
    "        for (doc_name, cos_) in topK:\n",
    "            print(\"\\t\" + doc_name + \" : {:.5f}\".format(cos_))\n",
    "\n",
    "        print('=' * 50)\n",
    "        print()  # new line\n",
    "    \n",
    "    # if true show documents to user!\n",
    "    if show_documents:\n",
    "        for (doc_name, cos_) in topK:\n",
    "            print(D[doc_name])\n",
    "            print()\n",
    "    \n",
    "    # if true return scores + retrieval time \n",
    "    if return_results and return_speed:\n",
    "        return (topK, retrieval_speed)\n",
    "    \n",
    "    # if true return scores\n",
    "    if return_results:\n",
    "        return topK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. *Efficient Retrieval*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1 intersection()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def intersection(sets):\n",
    "    \"\"\"Returns the intersection of all sets in the list sets. Requires\n",
    "   that the list sets contains at least one element, otherwise it\n",
    "   raises an error.\"\"\"\n",
    "\n",
    "    return reduce(set.intersection, [s for s in sets])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 pre_clustering()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pre_cluster(D, verbose=True):\n",
    "    \n",
    "    \"\"\"Some docString here\"\"\"\n",
    "\n",
    "#     cluster = {'leader1': [doc1, doc2,,,],\n",
    "#                'leader2': [doc4, doc5,,,]}\n",
    "\n",
    "    t0 = time()\n",
    "\n",
    "    cluster = dict()\n",
    "\n",
    "   # number of leaders is the square root of number of docs\n",
    "    num_leaders = math.trunc(math.sqrt(len(D)))\n",
    "\n",
    "   # randomly choose leaders\n",
    "    leaders = np.random.choice(list(D.keys()), size=num_leaders,\n",
    "                               replace=False)\n",
    "\n",
    "   # get list of non-leaders\n",
    "    non_leaders = []\n",
    "    for key in D.keys():\n",
    "        if key not in leaders:\n",
    "            non_leaders.append(key)\n",
    "\n",
    "   # delete non_leaders from D\n",
    "    D_leaders = copy.deepcopy(D)\n",
    "    for non_leader in non_leaders:\n",
    "        if non_leader in D_leaders.keys():\n",
    "            del D_leaders[non_leader]\n",
    "\n",
    "   # compute indexing based on document leader collection\n",
    "    idfs_leaders = compute_Idf(D_leaders, verbose=False)\n",
    "    tfidfs_leaders = compute_TfIdf(D_leaders, idfs_leaders,\n",
    "                                   verbose=False)\n",
    "    inverted_index_leaders = construct_invertedIndex(D_leaders,\n",
    "                                                     idfs_leaders, tfidfs_leaders, verbose=False)\n",
    "    doc_lengths_leaders = construct_docLengthDict(D_leaders,\n",
    "                                                  tfidfs_leaders, verbose=False)\n",
    "\n",
    "   # assign non_leaders to leader\n",
    "   # (treat each non_leader document d as query)\n",
    "    for doc in non_leaders:\n",
    "\n",
    "        similarity = cosine_scores(q=D[doc], D=D,\n",
    "                                   I=inverted_index_leaders,\n",
    "                                   L=doc_lengths_leaders,\n",
    "                                   idfDict=idfs_leaders)\n",
    "\n",
    "        if list(max(zip(similarity.values(), similarity.keys())))[1] \\\n",
    "                in cluster:\n",
    "            cluster[list(max(zip(similarity.values(),\n",
    "                                 similarity.keys())))[1]].append(doc)\n",
    "        else:\n",
    "            cluster[list(max(zip(similarity.values(),\n",
    "                                 similarity.keys())))[1]] = [doc]\n",
    "\n",
    "    if verbose:\n",
    "        print('Preclustering done in {:.4f}s.'.format(time() - t0))\n",
    "\n",
    "    return cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# *Evaluation*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_pAtRank(y_pred, y_true, atRank=10):\n",
    "    \n",
    "    \"\"\"Calculate precision at Rank k\"\"\"\n",
    "\n",
    "    retrieved_docs = list()  # holds relevant docID\n",
    "    rel_01 = list()\n",
    "\n",
    "    for i in range(len(y_pred)):\n",
    "        retrieved_docs.append(y_pred[i][0])\n",
    "\n",
    "    # convert into 0,1 vector\n",
    "    for i in range(len(retrieved_docs)):\n",
    "        if retrieved_docs[i] in y_true:\n",
    "            rel_01.append(1)\n",
    "        else:\n",
    "            rel_01.append(0)\n",
    "\n",
    "    # precision @Rank (by default p@10)\n",
    "    precisionAtRank = (sum(rel_01)) / atRank\n",
    "\n",
    "    return precisionAtRank"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_AveragePrecision(y_pred, y_true, k=None):\n",
    "    \n",
    "    \"\"\"Some docString here\"\"\"\n",
    "\n",
    "    retrieved_docs = list()             # holds relevant docID\n",
    "    rel_01 = list()\n",
    "    Pk_scores = list()                  # holds the precision scores at rank K\n",
    "\n",
    "    for i in range(len(y_pred)):\n",
    "        retrieved_docs.append(y_pred[i][0])\n",
    "\n",
    "    # convert into 0,1 vector\n",
    "    for i in range(len(retrieved_docs)):\n",
    "        if retrieved_docs[i] in y_true:\n",
    "            rel_01.append(1)\n",
    "        else:\n",
    "            rel_01.append(0)\n",
    "\n",
    "    # compute precision at rank k\n",
    "    for i in range(len(rel_01)):\n",
    "        if rel_01[i] == 1:\n",
    "            pAtK = sum(rel_01[:(i+1)]) / (i+1)\n",
    "            Pk_scores.append(pAtK)\n",
    "        else:\n",
    "            continue\n",
    "\n",
    "    # compute average precision across ranks\n",
    "    if k is None:\n",
    "        k = len(y_true)\n",
    "        \n",
    "    avgP = sum(Pk_scores) / k\n",
    "\n",
    "    return avgP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_nDCG(y_pred, y_true, variant=\"raw_scores\"):\n",
    "    \n",
    "    \"\"\"Some docString here\"\"\"\n",
    "\n",
    "    rel_012 = list()\n",
    "    retrieved_docIds = list()\n",
    "\n",
    "    # extract IDs of retrieved documents\n",
    "    for i in range(len(y_pred)):\n",
    "        retrieved_docIds.append(y_pred[i][0])\n",
    "\n",
    "    # convert gold standard into dictionary that is easier to use\n",
    "    y_trueDict = dict()\n",
    "    for i in range(len(y_true)):\n",
    "        key_ = y_true[i][0]\n",
    "        value_ = y_true[i][1]\n",
    "        y_trueDict.update({key_: value_})\n",
    "\n",
    "    # create vector that denotes the true relevance score for every retrieved document\n",
    "    for i in range(len(retrieved_docIds)):\n",
    "        if retrieved_docIds[i] in y_trueDict.keys():\n",
    "            if y_trueDict[retrieved_docIds[i]] == 2:\n",
    "                rel_012.append(2)\n",
    "            if y_trueDict[retrieved_docIds[i]] == 1:\n",
    "                rel_012.append(1)\n",
    "        else:\n",
    "            rel_012.append(0)\n",
    "    \n",
    "    if variant == \"raw_scores\":\n",
    "        DCG = 0.0\n",
    "\n",
    "        for idx in range(len(rel_012)):\n",
    "            i = idx + 1\n",
    "            score_ = (rel_012[idx]) / (np.log2(i + 1))\n",
    "            DCG += score_\n",
    "\n",
    "        # Calculate IDCG\n",
    "        ideal_ranking = sorted(list(y_trueDict.values()), reverse=True)\n",
    "\n",
    "        IDCG = 0.0\n",
    "        for idx in range(len(ideal_ranking)):\n",
    "            i = idx + 1\n",
    "            score_ = (ideal_ranking[idx]) / (np.log2(i + 1))\n",
    "            IDCG += score_\n",
    "\n",
    "        # Noralized Discounted Cumulative Gain (nDCG)\n",
    "        if IDCG == 0:\n",
    "            #print(\"Flag Error!\")\n",
    "            nDCG = 0\n",
    "        else:\n",
    "            nDCG = DCG / IDCG    \n",
    "    \n",
    "    \n",
    "    if variant == \"power\":\n",
    "        # Calcualte second variant of DCG\n",
    "        DCG2 = 0.0\n",
    "\n",
    "        for idx in range(len(rel_012)):\n",
    "            i = idx + 1\n",
    "            score_ = (np.power(2, rel_012[idx]) - 1) / (np.log2(i + 1))\n",
    "            DCG2 += score_\n",
    "\n",
    "        # Calculate IDCG\n",
    "        ideal_ranking = sorted(list(y_trueDict.values()), reverse=True)\n",
    "\n",
    "        IDCG2 = 0.0\n",
    "        for idx in range(len(ideal_ranking)):\n",
    "            i = idx + 1\n",
    "            score_ = (np.power(2, ideal_ranking[idx]) - 1) / (np.log2(i + 1))\n",
    "            IDCG2 += score_\n",
    "\n",
    "        # Noralized Discounted Cumulative Gain (nDCG)\n",
    "        if IDCG2 == 0:\n",
    "            nDCG = 0\n",
    "        else:\n",
    "            nDCG = DCG2 / IDCG2\n",
    "\n",
    "    return nDCG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
